{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"setup.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"VozdO74SWtcT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":134},"cellView":"both","outputId":"934ff3f5-0232-4f48-87f8-a0ad30432e99","executionInfo":{"status":"ok","timestamp":1531871607798,"user_tz":-480,"elapsed":41832,"user":{"displayName":"Michael Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100040677686947659586"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":22,"outputs":[{"output_type":"stream","text":["gpg: keybox '/tmp/tmp0tgfxklb/pubring.gpg' created\n","gpg: /tmp/tmp0tgfxklb/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","··········\n"],"name":"stdout"}]},{"metadata":{"id":"XTFwUyOuZhTs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WpYaKaik1YOa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install -q keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JqcyHaqR1dLy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":759},"outputId":"fe0549df-3675-4af0-ae9c-925ce59ba2d4","executionInfo":{"status":"ok","timestamp":1531870661946,"user_tz":-480,"elapsed":158926,"user":{"displayName":"Michael Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100040677686947659586"}}},"cell_type":"code","source":["!python3 drive/Colab/mnist_cnn.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 2s 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/12\n","2018-07-17 23:35:18.337521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2018-07-17 23:35:18.338104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","totalMemory: 11.17GiB freeMemory: 11.10GiB\n","2018-07-17 23:35:18.338150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n","2018-07-17 23:35:18.841195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2018-07-17 23:35:18.841370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n","2018-07-17 23:35:18.841404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n","2018-07-17 23:35:18.842052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10763 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","19840/60000 [========>.....................] - ETA: 12s - loss: 0.4965 - acc: 0.8483"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 14s 232us/step - loss: 0.2589 - acc: 0.9218 - val_loss: 0.0600 - val_acc: 0.9820\n","Epoch 2/12\n","60000/60000 [==============================] - 12s 192us/step - loss: 0.0880 - acc: 0.9738 - val_loss: 0.0381 - val_acc: 0.9870\n","Epoch 3/12\n","51456/60000 [========================>.....] - ETA: 1s - loss: 0.0666 - acc: 0.9803"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 11s 187us/step - loss: 0.0660 - acc: 0.9804 - val_loss: 0.0354 - val_acc: 0.9885\n","Epoch 4/12\n","60000/60000 [==============================] - 11s 187us/step - loss: 0.0523 - acc: 0.9836 - val_loss: 0.0323 - val_acc: 0.9891\n","Epoch 5/12\n","59008/60000 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9860"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 11s 189us/step - loss: 0.0462 - acc: 0.9860 - val_loss: 0.0283 - val_acc: 0.9905\n","Epoch 6/12\n","60000/60000 [==============================] - 11s 190us/step - loss: 0.0414 - acc: 0.9876 - val_loss: 0.0280 - val_acc: 0.9910\n","Epoch 7/12\n","60000/60000 [==============================] - 11s 188us/step - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0290 - val_acc: 0.9906\n","Epoch 8/12\n","  384/60000 [..............................] - ETA: 14s - loss: 0.0389 - acc: 0.9870"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 11s 190us/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.0281 - val_acc: 0.9915\n","Epoch 9/12\n","60000/60000 [==============================] - 12s 197us/step - loss: 0.0319 - acc: 0.9904 - val_loss: 0.0259 - val_acc: 0.9918\n","Epoch 10/12\n","43392/60000 [====================>.........] - ETA: 3s - loss: 0.0289 - acc: 0.9914"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 11s 191us/step - loss: 0.0292 - acc: 0.9912 - val_loss: 0.0341 - val_acc: 0.9892\n","Epoch 11/12\n","60000/60000 [==============================] - 11s 191us/step - loss: 0.0281 - acc: 0.9911 - val_loss: 0.0238 - val_acc: 0.9927\n","Epoch 12/12\n","55552/60000 [==========================>...] - ETA: 0s - loss: 0.0261 - acc: 0.9918"],"name":"stdout"},{"output_type":"stream","text":["60000/60000 [==============================] - 11s 191us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0267 - val_acc: 0.9917\n","Test loss: 0.02671625117767453\n","Test accuracy: 0.9917\n"],"name":"stdout"}]},{"metadata":{"id":"3M4McEclnktV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!ls -l drive1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LprOf3Tt2fBS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":941},"outputId":"40ffb8a2-7f6e-4599-8c72-51875d836a62","executionInfo":{"status":"ok","timestamp":1531871927961,"user_tz":-480,"elapsed":27425,"user":{"displayName":"Michael Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100040677686947659586"}}},"cell_type":"code","source":["# style transfer\n","from __future__ import print_function\n","from keras.preprocessing.image import load_img, img_to_array\n","from scipy.misc import imsave\n","import numpy as np\n","from scipy.optimize import fmin_l_bfgs_b\n","import time\n","import argparse\n","\n","from keras.applications import vgg16\n","from keras import backend as K\n","\n","base_image_path = \"drive/Colab/images/input.jpg\"\n","style_reference_image_path = \"drive/Colab/images/startnight.jpg\"\n","result_prefix = \"output\"\n","iterations = 2 # 10\n","\n","# 原圖與風格圖佔output比重\n","content_weight = 0.025\n","style_weight = 1.0\n","# 損失總差異預設值\n","total_variation_weight = 1.0\n","\n","# output 圖的寬高\n","width, height = load_img(base_image_path).size\n","img_nrows = 400\n","img_ncols = int(width * img_nrows / height)\n","\n","# 轉換成 VGG 16 input 格式\n","def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n","    img = img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = vgg16.preprocess_input(img)\n","    return img\n","\n","# 將特徵向量轉換成 image\n","def deprocess_image(x):\n","    if K.image_data_format() == 'channels_first':\n","        x = x.reshape((3, img_nrows, img_ncols))\n","        x = x.transpose((1, 2, 0))\n","    else:\n","        x = x.reshape((img_nrows, img_ncols, 3))\n","    # 設定RGB顏色的中心點 (Remove zero-center by mean pixel)\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    # 'BGR'->'RGB'\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","# 設定 Keras 變數 base_image = 原圖 向量\n","base_image = K.variable(preprocess_image(base_image_path))\n","# 設定 Keras 變數 style_reference_image = 風格圖 向量\n","style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n","\n","# 設定合成圖的起始值\n","if K.image_data_format() == 'channels_first':\n","    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n","else:\n","    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n","\n","# 合併原圖、風格圖、合成圖 向量\n","input_tensor = K.concatenate([base_image,\n","                              style_reference_image,\n","                              combination_image], axis=0)\n","\n","# 載入 VGG 16 模型，不包括加在最後3層的卷積層\n","model = vgg16.VGG16(input_tensor=input_tensor,\n","                    weights='imagenet', include_top=False)\n","\n","# print model information                    \n","print(model.summary())\n","\n","# save model pictures to VGG16.png                    \n","from keras.utils import plot_model\n","#plot_model(model, to_file='./VGG16.png')\n","\n","                    \n","# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n","# 讀取 VGG 16 模型的每一層的名稱與output\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","# 計算 風格 loss 的 gram matrix\n","def gram_matrix(x):\n","    if K.image_data_format() == 'channels_first':\n","        features = K.batch_flatten(x)\n","    else:\n","        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n","    gram = K.dot(features, K.transpose(features))\n","    return gram\n","\n","# 計算 風格 loss \n","def style_loss(style, combination):\n","    assert K.ndim(style) == 3\n","    assert K.ndim(combination) == 3\n","    S = gram_matrix(style)\n","    C = gram_matrix(combination)\n","    channels = 3\n","    size = img_nrows * img_ncols\n","    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n","\n","# 計算 content loss \n","def content_loss(base, combination):\n","    return K.sum(K.square(combination - base))\n","\n","# the 3rd loss function, total variation loss,\n","# designed to keep the generated image locally coherent\n","\n","\n","# 計算 損失總差異(total variation loss)，以利合成圖的連貫性\n","def total_variation_loss(x):\n","    assert K.ndim(x) == 4\n","    if K.image_data_format() == 'channels_first':\n","        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n","        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n","    else:\n","        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n","        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n","    return K.sum(K.pow(a + b, 1.25))\n","\n","# 彙總上面三項的損失(loss)\n","loss = K.variable(0.)\n","layer_features = outputs_dict['block5_conv2']\n","base_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","loss += content_weight * content_loss(base_image_features,\n","                                      combination_features)\n","\n","feature_layers = ['block1_conv1', 'block2_conv1',\n","                  'block3_conv1', 'block4_conv1',\n","                  'block5_conv1']\n","for layer_name in feature_layers:\n","    layer_features = outputs_dict[layer_name]\n","    style_reference_features = layer_features[1, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_reference_features, combination_features)\n","    loss += (style_weight / len(feature_layers)) * sl\n","loss += total_variation_weight * total_variation_loss(combination_image)\n","\n","# 計算合成圖的梯度(gradients)\n","grads = K.gradients(loss, combination_image)\n","\n","# 建立 Keras function API 模型\n","outputs = [loss]\n","if isinstance(grads, (list, tuple)):\n","    outputs += grads\n","else:\n","    outputs.append(grads)\n","\n","f_outputs = K.function([combination_image], outputs)\n","\n","\n","# 依梯度下降法，評估模型\n","def eval_loss_and_grads(x):\n","    if K.image_data_format() == 'channels_first':\n","        x = x.reshape((1, 3, img_nrows, img_ncols))\n","    else:\n","        x = x.reshape((1, img_nrows, img_ncols, 3))\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    if len(outs[1:]) == 1:\n","        grad_values = outs[1].flatten().astype('float64')\n","    else:\n","        grad_values = np.array(outs[1:]).flatten().astype('float64')\n","    return loss_value, grad_values\n","\n","# 評估模型類別\n","# this Evaluator class makes it possible\n","# to compute loss and gradients in one pass\n","# while retrieving them via two separate functions,\n","# \"loss\" and \"grads\". This is done because scipy.optimize\n","# requires separate functions for loss and gradients,\n","# but computing them separately would be inefficient.\n","class Evaluator(object):\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values\n","\n","# 執行模型評估\n","evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","# 在每一週期產生合成圖\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # 儲存每一週期的output合成圖\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix + '_at_iteration_%d.png' % i\n","    imsave(fname, img)\n","    end_time = time.time()\n","    print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, None, None, 3)     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n","Start of iteration 0\n","Current loss value: 7322010600.0\n","Image saved as output_at_iteration_0.png\n","Iteration 0 completed in 13s\n","Start of iteration 1\n","Current loss value: 4155657200.0\n","Image saved as output_at_iteration_1.png\n","Iteration 1 completed in 10s\n"],"name":"stdout"}]},{"metadata":{"id":"OK5mp3fvnX_T","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"071b671d-bfdd-4616-b6cc-f68443913db3","executionInfo":{"status":"ok","timestamp":1531871818546,"user_tz":-480,"elapsed":2632,"user":{"displayName":"Michael Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100040677686947659586"}}},"cell_type":"code","source":["!ls -l drive/Colab/images"],"execution_count":26,"outputs":[{"output_type":"stream","text":["total 475\r\n","-rw-r--r-- 1 root root 277368 Jul 17 23:37 input.jpg\r\n","-rw-r--r-- 1 root root 208857 Jul 17 23:56 startnight.jpg\r\n"],"name":"stdout"}]},{"metadata":{"id":"TtVll-xIoTjU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":118},"outputId":"9b829281-68c1-48cb-d91f-437560c984c9","executionInfo":{"status":"ok","timestamp":1531871954967,"user_tz":-480,"elapsed":2784,"user":{"displayName":"Michael Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100040677686947659586"}}},"cell_type":"code","source":["!ls -l\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["total 688\r\n","drwxr-xr-x 1 root root   4096 Jul 17 23:33 datalab\r\n","drwxr-xr-x 2 root root   4096 Jul 17 23:34 drive\r\n","drwxr-xr-x 2 root root   4096 Jul 17 23:53 drive1\r\n","-rw-r--r-- 1 root root 345223 Jul 17 23:58 output_at_iteration_0.png\r\n","-rw-r--r-- 1 root root 336072 Jul 17 23:58 output_at_iteration_1.png\r\n"],"name":"stdout"}]},{"metadata":{"id":"YxDs8Zz0rvzc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!cp out*.* drive/Colab/images"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RF9bWDC-r6Ls","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}